{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "# Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préliminaires**: Clone de votre repo et imports"
      ],
      "metadata": {
        "id": "hfkMtaHleKAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Redazh/exam_2025.git\n",
        "! cp exam_2025/utils/utils_exercices.py .\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "xiD_cI-geJjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a207d9-8e42-42d3-c111-8e1daf9b4de9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exam_2025'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 59 (delta 21), reused 20 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 1.41 MiB | 5.00 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clef personnelle pour la partie théorique**\n",
        "\n",
        "Dans la cellule suivante, choisir un entier entre 100 et 1000 (il doit être personnel). Cet entier servira de graine au générateur de nombres aléatoire a conserver pour tous les exercices.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3ga_6BNc5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeed = 200"
      ],
      "metadata": {
        "id": "PrCTHM4od5UZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "TRWBLVpCWC06"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "\\\n",
        "\n",
        "**Exercice 1** *Une relation linéaire*\n",
        "\n",
        "La fonction *generate_dataset* fournit deux jeux de données (entraînement et test). Pour chaque jeu de données, la clef 'inputs' donne accès à un tableau numpy (numpy array) de prédicteurs empilés horizontalement : chaque ligne $i$ contient trois prédicteurs $x_i$, $y_i$ et $z_i$. La clef 'targets' renvoie le vecteur des cibles $t_i$. \\\n",
        "\n",
        "Les cibles sont liées aux prédicteurs par le modèle:\n",
        "$$ t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon$$ où $\\epsilon \\sim \\mathcal{N}(0,\\eta)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset, Dataset1\n",
        "train_set, test_set = generate_dataset(mySeed)"
      ],
      "metadata": {
        "id": "gEQmgTI8my8i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Par quelle méthode simple peut-on estimer les coefficients $\\theta_k$ ? La mettre en oeuvre avec la librairie python de votre choix."
      ],
      "metadata": {
        "id": "q5XZTrXNk12K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "une méthode simple consiste à utiliser une régression linéaire pour estimer ces coefficients."
      ],
      "metadata": {
        "id": "AlPBjdAbVSig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "# Extraction des prédicteurs (inputs) et des cibles (targets)\n",
        "X_train = train_set['inputs']  # Shape: (n_samples, 3)\n",
        "T_train = train_set['targets']  # Shape: (n_samples,)\n",
        "\n",
        "# Création et entraînement du modèle de régression linéaire\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, T_train)\n",
        "\n",
        "# Extraction des coefficients estimés\n",
        "Theta_linear_0 = model.intercept_  # theta_0\n",
        "Theta_linear_rest = model.coef_    # Coefficients theta_1, theta_2, theta_3\n",
        "\n",
        "print(\"Theta_0 :\", Theta_linear_0)\n",
        "print(\"Coefficients (theta_1, theta_2, theta_3) :\", Theta_linear_rest)\n"
      ],
      "metadata": {
        "id": "HITtUqHhFMkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebe3b64-a33b-4d98-c741-f82092c5d8e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta_0 : 10.078764034363882\n",
            "Coefficients (theta_1, theta_2, theta_3) : [1.95156862 1.94842221 3.59966699]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MXGXg8tlPULY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans les cellules suivantes, on se propose d'estimer les $\\theta_k$ grâce à un réseau de neurones entraîné par SGD. Quelle architecture s'y prête ? Justifier en termes d'expressivité et de performances en généralisation puis la coder dans la cellule suivante."
      ],
      "metadata": {
        "id": "CH_Z5ZEIlQPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture adaptée :\n",
        "\n",
        "*   Une seule couche linéaire prenant en entrée x,y,z et produisant une sortie t.\n",
        "*   Pas besoin d'activation non linéaire (comme ReLU), car le modèle est linéaire.\n",
        "\n"
      ],
      "metadata": {
        "id": "9i8R-FwGW6Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Expressivité : Le modèle doit être capable d'apprendre une relation linéaire entre les prédicteurs (x,y,z) et les cibles (t). Une architecture avec une seule couche entièrement connectée (nn.Linearnn.Linear) est suffisante pour capturer cette relation.\n",
        "*   Performances en généralisation : Une architecture simple limite le risque de surapprentissage (overfitting) et est bien adaptée à des données générées selon un modèle linéaire.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HJF2frEZXMAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset et dataloader :\n",
        "dataset = Dataset1(train_set['inputs'], train_set['targets'])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "import torch.nn as nn\n",
        "# A coder :\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        # Une seule couche linéaire (entrée 3 -> sortie 1)\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "PPx543blnxdb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Entraîner cette architecture à la tâche de régression définie par les entrées et sorties du jeu d'entraînement (compléter la cellule ci-dessous)."
      ],
      "metadata": {
        "id": "g6BSTBitpGBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "mySimpleNet = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(mySimpleNet.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = mySimpleNet(batch_inputs)\n",
        "        loss = criterion(outputs, batch_targets.unsqueeze(1))\n",
        "\n",
        "        loss.backward()       # Compute gradients\n",
        "        optimizer.step()      # Update model parameters\n",
        "\n",
        "    # Print the loss for every 50 epochs\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "Wjfa2Z4RoPO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a30b5e-fc84-4ce2-9bf2-c967cb3c746c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 3.6527\n",
            "Epoch [100/500], Loss: 5.2404\n",
            "Epoch [150/500], Loss: 3.7363\n",
            "Epoch [200/500], Loss: 3.2035\n",
            "Epoch [250/500], Loss: 3.4469\n",
            "Epoch [300/500], Loss: 3.6447\n",
            "Epoch [350/500], Loss: 3.4577\n",
            "Epoch [400/500], Loss: 3.6525\n",
            "Epoch [450/500], Loss: 3.8471\n",
            "Epoch [500/500], Loss: 4.2082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Où sont alors stockées les estimations des  $\\theta_k$ ? Les extraire du réseau *mySimpleNet* dans la cellule suivante."
      ],
      "metadata": {
        "id": "OZwKogEEp2Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Theta_neural_rest = mySimpleNet.linear.weight.data.numpy().flatten()  # Poids : theta_1, theta_2, theta_3\n",
        "Theta_neural_0 = mySimpleNet.linear.bias.data.numpy().item()            # Biais : theta_0\n",
        "\n",
        "print(\"Theta_0 (biais) :\", Theta_neural_0)\n",
        "print(\"Theta_1, Theta_2, Theta_3 :\", Theta_neural_rest)"
      ],
      "metadata": {
        "id": "EjgWp1y1rseb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc4aaf2-95da-4fbf-ffa8-b1e0510638a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theta_0 (biais) : 10.078777313232422\n",
            "Theta_1, Theta_2, Theta_3 : [1.9517587 1.9488926 3.599925 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Tester ces estimations sur le jeu de test et comparer avec celles de la question 1. Commentez."
      ],
      "metadata": {
        "id": "pEB-V-oOrJED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Jeu de test\n",
        "X_test = test_set['inputs']  # Prédicteurs\n",
        "T_test = test_set['targets']  # Cibles\n",
        "\n",
        "\n",
        "\n",
        "# Calcul des prédictions\n",
        "T_pred_linear = Theta_linear_0 + X_test @ Theta_linear_rest\n",
        "\n",
        "\n",
        "# Calcul des prédictions\n",
        "T_pred_neural = Theta_neural_0 + X_test @ Theta_neural_rest\n",
        "\n",
        "# --- 3. Calcul des erreurs quadratiques moyennes ---\n",
        "mse_linear = mean_squared_error(T_test, T_pred_linear)\n",
        "mse_neural = mean_squared_error(T_test, T_pred_neural)\n",
        "\n",
        "print(f\"MSE Régression linéaire avec mean_squared_error: {mse_linear:.6f}\")\n",
        "print(f\"MSE Réseau de neurones avec mean_squared_error: {mse_neural:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jep6sZE1ZPAp",
        "outputId": "7f17316f-9f01-472d-ada7-ac1c42f4ada5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Régression linéaire avec mean_squared_error: 4.009261\n",
            "MSE Réseau de neurones avec mean_squared_error: 4.009149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion des données en tenseurs PyTorch\n",
        "T_test_tensor = torch.tensor(T_test, dtype=torch.float32)  # Cibles réelles\n",
        "T_pred_linear_tensor = torch.tensor(T_pred_linear, dtype=torch.float32)  # Prédictions régression linéaire\n",
        "T_pred_neural_tensor = torch.tensor(T_pred_neural, dtype=torch.float32)  # Prédictions réseau de neurones\n",
        "\n",
        "# Calcul de la MSE avec `criterion`\n",
        "mse_linear = criterion(T_pred_linear_tensor, T_test_tensor).item()\n",
        "mse_neural = criterion(T_pred_neural_tensor, T_test_tensor).item()\n",
        "\n",
        "print(f\"MSE Régression linéaire (avec criterion): {mse_linear:.6f}\")\n",
        "print(f\"MSE Réseau de neurones (avec criterion): {mse_neural:.6f}\")\n"
      ],
      "metadata": {
        "id": "lXjalXPZagfx",
        "outputId": "5e84bc11-a54e-4992-ee79-3ede057e8492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Régression linéaire (avec criterion): 4.009261\n",
            "MSE Réseau de neurones (avec criterion): 4.009149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les deux méthodes donnent des performances quasiment identiques."
      ],
      "metadata": {
        "id": "ZQwOGiVsZsr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "VvV2jIrBNtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2** *Champ réceptif et prédiction causale*"
      ],
      "metadata": {
        "id": "CpRvXCaAtsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini dans la cellule suivante est utilisé pour faire le lien entre les valeurs $(x_{t' \\leq t})$ d'une série temporelle d'entrée et la valeur présente $y_t$ d'une série temporelle cible."
      ],
      "metadata": {
        "id": "8JG9wTfK5TBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from utils_exercices import Outconv, Up_causal, Down_causal\n",
        "\n",
        "class Double_conv_causal(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2, with causal convolutions that preserve input size'''\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1):\n",
        "        super(Double_conv_causal, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class causalFCN(nn.Module):\n",
        "    def __init__(self, dilation=1):\n",
        "        super(causalFCN, self).__init__()\n",
        "        size = 64\n",
        "        n_channels = 1\n",
        "        n_classes = 1\n",
        "        self.inc = Double_conv_causal(n_channels, size)\n",
        "        self.down1 = Down_causal(size, 2*size)\n",
        "        self.down2 = Down_causal(2*size, 4*size)\n",
        "        self.down3 = Down_causal(4*size, 8*size, pooling_kernel_size=5, pooling_stride=5)\n",
        "        self.down4 = Down_causal(8*size, 4*size, pooling=False, dilation=2)\n",
        "        self.up2 = Up_causal(4*size, 2*size, kernel_size=5, stride=5)\n",
        "        self.up3 = Up_causal(2*size, size)\n",
        "        self.up4 = Up_causal(size, size)\n",
        "        self.outc = Outconv(size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up2(x5, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "# Exemple d'utilisation\n",
        "model = causalFCN()\n",
        "# Série temporelle d'entrée (x_t):\n",
        "input_tensor1 = torch.rand(1, 1, 10000)\n",
        "# Série temporelle en sortie f(x_t):\n",
        "output = model(input_tensor1)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "fIbU1EJT1MM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb14a2b-1451-439e-d419-0ffd76c27979"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** De quel type de réseau de neurones s'agit-il ? Combien de paramètres la couche self.Down1 compte-t-elle (à faire à la main) ?\n",
        "Combien de paramètres le réseau entier compte-t-il (avec un peu de code) ?"
      ],
      "metadata": {
        "id": "-mNnsYU-7R7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce réseau est un Fully Convolutional Network (FCN) avec des convolutions causales adaptées aux séries temporelles."
      ],
      "metadata": {
        "id": "YRlPwNC1bZy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.down1)"
      ],
      "metadata": {
        "id": "1dh9NcdceAYE",
        "outputId": "235f8580-bc06-4384-8938-99ee8916d703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Down_causal(\n",
            "  (mpconv): Sequential(\n",
            "    (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (1): Double_conv_causal(\n",
            "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nb de paramètres dans self.Down1: (calcul \"à la main\")\n",
        "\n",
        "# Dimensions pour la première convolution\n",
        "in_channels_1 = 64\n",
        "out_channels_1 = 2*64\n",
        "kernel_size_1 = 3\n",
        "\n",
        "# Calcul des paramètres pour la première convolution\n",
        "conv1_params = (in_channels_1 * kernel_size_1 + 1) * out_channels_1\n",
        "print(f\"Conv1 params = ({in_channels_1} * {kernel_size_1} + 1) * {out_channels_1} = {conv1_params}\")\n",
        "\n",
        "# BatchNorm pour la première convolution\n",
        "bn1_params = 2 * out_channels_1\n",
        "print(f\"BatchNorm1 params = 2 * {out_channels_1} = {bn1_params}\")\n",
        "\n",
        "# Dimensions pour la deuxième convolution\n",
        "in_channels_2 = 128\n",
        "out_channels_2 = 128\n",
        "kernel_size_2 = 3\n",
        "\n",
        "# Calcul des paramètres pour la deuxième convolution\n",
        "conv2_params = (in_channels_2 * kernel_size_2 + 1) * out_channels_2\n",
        "print(f\"Conv2 params = ({in_channels_2} * {kernel_size_2} + 1) * {out_channels_2} = {conv2_params}\")\n",
        "\n",
        "# BatchNorm pour la deuxième convolution\n",
        "bn2_params = 2 * out_channels_2\n",
        "print(f\"BatchNorm2 params = 2 * {out_channels_2} = {bn2_params}\")\n",
        "\n",
        "# Total des paramètres pour Double_conv_causal\n",
        "total_params = conv1_params + bn1_params + conv2_params + bn2_params\n",
        "print(f\"Total params in Double_conv_causal = {conv1_params} + {bn1_params} + {conv2_params} + {bn2_params} = {total_params}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qlYxUf6U9vH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1606d359-405b-45c1-e836-90c817c83ca5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv1 params = (64 * 3 + 1) * 128 = 24704\n",
            "BatchNorm1 params = 2 * 128 = 256\n",
            "Conv2 params = (128 * 3 + 1) * 128 = 49280\n",
            "BatchNorm2 params = 2 * 128 = 256\n",
            "Total params in Double_conv_causal = 24704 + 256 + 49280 + 256 = 74496\n",
            "Nombre total de paramètres dans le réseau : 2872641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nb de paramètres au total:\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Nombre total de paramètres dans le réseau : {total_params}\")"
      ],
      "metadata": {
        "id": "_7PuGtO2eXYL",
        "outputId": "ed5488d5-4377-41b5-b8c1-a345cc17aca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de paramètres dans le réseau : 2872641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Par quels mécanismes la taille du vecteur d'entrée est-elle réduite ? Comment est-elle restituée dans la deuxième partie du réseau ?"
      ],
      "metadata": {
        "id": "I4D46A0-8LaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La taille du vecteur d'entrée est réduite par MaxPool1d et les convolutions avec stride dans les couches Down_causal. Elle est restituée par des convolutions transposées dans Up_causal et des skip connections qui combinent les informations locales et globales."
      ],
      "metadata": {
        "id": "k3KsqAh4fKzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Par quels mécanismes le champ réceptif est-il augmenté ? Préciser par un calcul la taille du champ réceptif en sortie de *self.inc*."
      ],
      "metadata": {
        "id": "SVNeFnm88yV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour augmenter le champ réceptif, le réseau utilise les mécanismes suivants :\n",
        "\n",
        "*    Convolutions dilatées dans Double_conv_causal, où le paramètre dilation agrandit l'espacement entre les valeurs du noyau sans augmenter le nombre de paramètres.\n",
        "*    Taille des noyaux (kernel_size) : Les noyaux kernel_size=3kernel_size=3 augmentent progressivement le champ réceptif.\n",
        "*    Padding causal : Ajouté par F.pad pour maintenir la causalité tout en préservant la taille de la séquence."
      ],
      "metadata": {
        "id": "2sXS5vWqffG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.inc)"
      ],
      "metadata": {
        "id": "3qW-nHYAgH4f",
        "outputId": "761ea150-e6f7-4c05-d5bf-7dd8b1d9b0e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Double_conv_causal(\n",
            "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
            "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
            "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation des paramètres\n",
        "kernel_size1 = 3  # Taille du noyau de conv1\n",
        "dilation1 = 1     # Dilatation de conv1\n",
        "stride1 = 1       # Stride de conv1\n",
        "\n",
        "kernel_size2 = 3  # Taille du noyau de conv2\n",
        "dilation2 = 1     # Dilatation de conv2\n",
        "stride2 = 1       # Stride de conv2\n",
        "\n",
        "# Champ réceptif pour la première convolution\n",
        "receptive_field1 = kernel_size1\n",
        "print(f\"Champ réceptif après conv1 = {receptive_field1}\")\n",
        "\n",
        "# Champ réceptif pour la deuxième convolution\n",
        "receptive_field2 = kernel_size2 + (receptive_field1 - 1) * dilation2\n",
        "print(f\"Champ réceptif après conv2 = {receptive_field2}\")\n",
        "\n",
        "# Résultat final\n",
        "print(f\"Champ réceptif en sortie de self.inc = {receptive_field2}\")\n"
      ],
      "metadata": {
        "id": "iNwguqLRfzxh",
        "outputId": "6f0e5150-227a-4667-c860-f265ffd0253b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Champ réceptif après conv1 = 3\n",
            "Champ réceptif après conv2 = 5\n",
            "Champ réceptif en sortie de self.inc = 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Par un bout de code, déterminer empiriquement la taille du champ réceptif associé à la composante $y_{5000}$ du vecteur de sortie. (Indice: considérer les sorties associées à deux inputs qui ne diffèrent que par une composante...)"
      ],
      "metadata": {
        "id": "TVVcBPuA9EP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation du modèle\n",
        "model.eval()  # Mode évaluation pour désactiver les dropouts\n",
        "\n",
        "# Création de deux entrées identiques\n",
        "input_length = 10000\n",
        "input_tensor1 = torch.zeros(1, 1, input_length)\n",
        "input_tensor2 = input_tensor1.clone()\n",
        "\n",
        "# Modification d'une composante unique dans input_tensor2\n",
        "index_to_modify = 5000\n",
        "input_tensor2[0, 0, index_to_modify] = 1.0\n",
        "\n",
        "# Passage des deux entrées dans le modèle\n",
        "output1 = model(input_tensor1)\n",
        "output2 = model(input_tensor2)"
      ],
      "metadata": {
        "id": "RANGWLkrhb_O"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passage des deux entrées dans le modèle\n",
        "model.eval()  # Mode évaluation (désactive le dropout, etc.)\n",
        "with torch.no_grad():\n",
        "    output1 = model(input_tensor1)  # Sortie associée à input_tensor1\n",
        "    output2 = model(input_tensor2)  # Sortie associée à input_tensor2\n",
        "\n",
        "# Recherche des composantes affectées\n",
        "affected_indices = torch.nonzero((output1 - output2).abs() > 1e-6).squeeze()\n",
        "\n",
        "# Affichage des résultats\n",
        "print(f\"Indices affectés dans la sortie : {affected_indices.tolist()}\")\n",
        "print(f\"Taille empirique du champ réceptif pour y_5000 : {affected_indices.max().item() - affected_indices.min().item() + 1}\")"
      ],
      "metadata": {
        "id": "69WMWCSZAg5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ca827a-19f8-4d0f-b2db-2e09d42cf6c2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices affectés dans la sortie : [[0, 0, 5000], [0, 0, 5001], [0, 0, 5002], [0, 0, 5003], [0, 0, 5004], [0, 0, 5005], [0, 0, 5006], [0, 0, 5007], [0, 0, 5008], [0, 0, 5009], [0, 0, 5010], [0, 0, 5011], [0, 0, 5012], [0, 0, 5013], [0, 0, 5014], [0, 0, 5015], [0, 0, 5016], [0, 0, 5017], [0, 0, 5018], [0, 0, 5019], [0, 0, 5020], [0, 0, 5021], [0, 0, 5022], [0, 0, 5024]]\n",
            "Taille empirique du champ réceptif pour y_5000 : 5025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** $y_{5000}$ dépend-elle des composantes $x_{t, \\space t > 5000}$ ? Justifier de manière empirique puis préciser la partie du code de Double_conv_causal qui garantit cette propriété de \"causalité\" en justifiant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "gZ37skwm-Vpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de deux entrées identiques\n",
        "input_length = 10000\n",
        "input_tensor1 = torch.zeros(1, 1, input_length)  # Entrée initiale\n",
        "input_tensor2 = input_tensor1.clone()\n",
        "\n",
        "# Modifier uniquement les composantes t > 5000\n",
        "input_tensor2[0, 0, 5001:] = 1.0  # Perturber les composantes après t=5000\n",
        "\n",
        "# Passage dans le modèle\n",
        "output1 = model(input_tensor1)  # Sortie pour l'entrée initiale\n",
        "output2 = model(input_tensor2)  # Sortie pour l'entrée perturbée\n",
        "\n",
        "# Vérifier si y5000 est affecté\n",
        "if torch.allclose(output1[0, 0, 5000], output2[0, 0, 5000]):\n",
        "    print(\"y5000 ne dépend pas des composantes xt avec t > 5000 (causalité respectée).\")\n",
        "else:\n",
        "    print(\"y5000 dépend des composantes xt avec t > 5000 (causalité violée).\")\n"
      ],
      "metadata": {
        "id": "PeooRYE-ATGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6065a6-30e2-4303-fbae-a471e93b60fe"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y5000 ne dépend pas des composantes xt avec t > 5000 (causalité respectée).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La causalité est assurée par l'utilisation de padding causal dans la méthode forward de Double_conv_causal : `x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))`\n",
        "\n",
        "\n",
        "*   F.pad ajoute des zéros uniquement à gauche de la séquence `((kernel_size−1)*dilation(kernel_size−1)×dilation)`.Cela garantit que la convolution ne \"voit\" que les éléments de xt​ pour t≤t_actuel​.\n",
        "*   e padding causal est appliqué avant chaque convolution dans Double_conv_causal.\n",
        "\n"
      ],
      "metadata": {
        "id": "LlXoaF8tjUEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "inQBIjm0iLNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "qV52tusgNn6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "Exercice 3: \"Ranknet loss\""
      ],
      "metadata": {
        "id": "bm-sRzmfqc2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un [article récent](https://arxiv.org/abs/2403.14144) revient sur les progrès en matière de learning to rank. En voilà un extrait :"
      ],
      "metadata": {
        "id": "Wl8wUjsSM57D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nanopiero/exam_2025/refs/heads/main/utils/png_exercice3.PNG\" alt=\"extrait d'un article\" width=\"800\">"
      ],
      "metadata": {
        "id": "SDZUXMlSDpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Qu'est-ce que les auteurs appellent \"positive samples\" et \"negative samples\" ? Donner un exemple."
      ],
      "metadata": {
        "id": "9NzV1PbMNyuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le contexte du Learning to Rank (LTR), les auteurs font référence à :\n",
        "\n",
        "*    Positive samples : Des documents ou items qui sont pertinents par rapport à une requête donnée.\n",
        "*    Negative samples : Des documents ou items qui sont non pertinents ou moins pertinents par rapport à une requête donnée."
      ],
      "metadata": {
        "id": "p_CG372XjyIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prenons un moteur de recherche comme exemple :\n",
        "\n",
        "*    Une requête utilisateur : \"Meilleures recettes de gâteau au chocolat\".\n",
        "*.   Ensemble de résultats potentiels :\n",
        "        Une page contenant une recette de gâteau au chocolat (pertinent → positive sample).\n",
        "        Une page sur des gâteaux aux fruits (moins pertinent → negative sample).\n",
        "        Une page sur la météo (non pertinent → negative sample).\n",
        "\n",
        "Le modèle LTR vise à classer les documents de manière à ce que les positive samples soient classés plus haut que les negative samples dans les résultats."
      ],
      "metadata": {
        "id": "1TeI2WcEj3YN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans l'expression de $\\mathcal{L}_{RankNet}$, d'où proviennent les $z_i$ ? Que représentent-ils ?  "
      ],
      "metadata": {
        "id": "yIKQ5Eo9OnPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans l'expression de LRankNetLRankNet​, les zizi​ proviennent du modèle de scoring utilisé pour attribuer un score à chaque document (ou item) en fonction de sa pertinence vis-à-vis d'une requête donnée.\n"
      ],
      "metadata": {
        "id": "3KQ2T-cmkJI6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "zi​ est le score de pertinence prédite pour un document ii par le modèle.\n",
        "Ces scores sont utilisés pour comparer les documents entre eux dans une approche pairwise (par paires).\n",
        "Un score plus élevé (zi>zj​) signifie que le modèle estime que le document i est plus pertinent que le document j."
      ],
      "metadata": {
        "id": "GGcweO2OkKES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Pourquoi cette expression conduit-elle à ce que, après apprentissage, \"the estimated\n",
        "value of positive samples is greater than that of negative samples\n",
        "for each pair of positive/negative samples\" ?"
      ],
      "metadata": {
        "id": "r74fWiyvPb7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'expression de LRankNetLRankNet​ pousse le modèle à maximiser la probabilité σ(zi−zj), où zi​ est le score d'un positive sample et zj​ celui d'un negative sample.\n",
        "\n",
        "En minimisant la perte, le modèle apprend à augmenter zi​ par rapport à zj​, ce qui garantit qu'après apprentissage, les scores des positive samples sont systématiquement supérieurs à ceux des negative samples pour chaque paire."
      ],
      "metadata": {
        "id": "aqQfiWaGkatX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Dans le cadre d'une approche par deep learning, quels termes utilise-t-on pour qualifier les réseaux de neurones exploités et la modalité suivant laquelle ils sont entraînés ?"
      ],
      "metadata": {
        "id": "pk1EIi_VVi3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le cadre d'une approche par deep learning pour le Learning to Rank, on qualifie les réseaux de neurones comme des modèles pairwise (pairwise learning-to-rank models). La modalité d'entraînement est dite supervisée, car le modèle est entraîné à partir de paires de données avec des relations d'ordre explicites (positive > negative)."
      ],
      "metadata": {
        "id": "E5Kq-PnikmC5"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}